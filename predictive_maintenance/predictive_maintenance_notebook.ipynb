{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b745dfbe",
   "metadata": {},
   "source": [
    "# Predictive Maintenance â€” Predict failures using sensor time-series\n",
    "\n",
    "**Goal:** Predict imminent machinery failure (classification) using vibration, temperature, and pressure sensor data. This notebook includes data generation, preprocessing, feature engineering, RandomForest/XGBoost baseline, and an LSTM sequence model.\n",
    "\n",
    "**Files:** `sensor_data.csv` (synthetic), `requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f50275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic dataset\n",
    "df = pd.read_csv('sensor_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d224b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA: failure rate and sensors distribution\n",
    "print('Shape:', df.shape)\n",
    "print('Failure rate:', df.failure.mean())\n",
    "display(df.groupby('time').failure.mean().rolling(5).mean().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9776bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: aggregate windows per machine-time to predict failure at current timestep.\n",
    "# We'll create rolling stats per machine (mean, std) for last 10 timesteps and use them for classification.\n",
    "df_sorted = df.sort_values(['machine_id','time']).copy()\n",
    "for col in ['vibration','temperature','pressure']:\n",
    "    df_sorted[f'{col}_rmean'] = df_sorted.groupby('machine_id')[col].rolling(window=10, min_periods=1).mean().reset_index(0,drop=True)\n",
    "    df_sorted[f'{col}_rstd'] = df_sorted.groupby('machine_id')[col].rolling(window=10, min_periods=1).std().reset_index(0,drop=True).fillna(0)\n",
    "    \n",
    "features = [c for c in df_sorted.columns if c.endswith('_rmean') or c.endswith('_rstd')]\n",
    "X = df_sorted[features]\n",
    "y = df_sorted['failure']\n",
    "print('Features used:', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dacf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split ensuring no leakage (by machine)\n",
    "machines = df_sorted['machine_id'].unique()\n",
    "train_machines, test_machines = train_test_split(machines, test_size=0.3, random_state=42)\n",
    "train_mask = df_sorted['machine_id'].isin(train_machines)\n",
    "X_train, X_test = X[train_mask], X[~train_mask]\n",
    "y_train, y_test = y[train_mask], y[~train_mask]\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "print(X_train_s.shape, X_test_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_s, y_train)\n",
    "pred = rf.predict(X_test_s)\n",
    "print(classification_report(y_test, pred))\n",
    "print('ROC AUC:', roc_auc_score(y_test, rf.predict_proba(X_test_s)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fac0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "feat_imp = sorted(zip(features, importances), key=lambda x: x[1], reverse=True)[:10]\n",
    "print('Top features:', feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79098098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM approach: convert per-machine sequences into samples\n",
    "# We'll create sequences of length 30 timesteps with corresponding label = whether failure occurs in that window.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "SEQ_LEN = 30\n",
    "seqs = []\n",
    "labels = []\n",
    "grouped = df.sort_values(['machine_id','time']).groupby('machine_id')\n",
    "for name, g in grouped:\n",
    "    arr = g[['vibration','temperature','pressure']].values\n",
    "    labs = g['failure'].values\n",
    "    for i in range(len(arr)-SEQ_LEN):\n",
    "        seqs.append(arr[i:i+SEQ_LEN])\n",
    "        labels.append(1 if labs[i+SEQ_LEN-1]==1 else 0)\n",
    "seqs = np.array(seqs)\n",
    "labels = np.array(labels)\n",
    "print('Sequences:', seqs.shape, 'Labels distribution:', labels.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810834fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split by machines for LSTM\n",
    "# We'll shuffle but keep proportion\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_seq_train, X_seq_test, y_seq_train, y_seq_test = train_test_split(seqs, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "# simple LSTM model\n",
    "model = Sequential([Masking(mask_value=0., input_shape=(SEQ_LEN,3)),\n",
    "                    LSTM(64, return_sequences=False),\n",
    "                    Dense(1, activation='sigmoid')])\n",
    "model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['AUC'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit for a few epochs (adjust epochs for real runs)\n",
    "history = model.fit(X_seq_train, y_seq_train, validation_data=(X_seq_test, y_seq_test), epochs=6, batch_size=64)\n",
    "print('Eval:')\n",
    "print(model.evaluate(X_seq_test, y_seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4d407",
   "metadata": {},
   "source": [
    "## Save artifacts\n",
    "You can save `scaler`, `rf` and `model` (LSTM) using joblib / tensorflow.save for production use."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
